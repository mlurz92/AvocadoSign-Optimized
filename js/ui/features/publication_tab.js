import { getElement, clearContainer, createElement } from '../../utils/dom_helpers.js';
import { formatNumber } from '../../utils/helpers.js';
import { calculateDiagnosticMetrics, calculateRocCurve, mcnemarTest, delongTest } from '../../services/statistics_service.js';
import { studyCriteria, evaluatePatient } from '../../core/criteria_manager.js';

function getFullStatistics(state) {
    const { processedData, bruteForce } = state;
    if (!processedData || processedData.length === 0) return null;

    const allStats = {};
    const groundTruth = processedData.map(p => p.groundTruth);
    const criteriaToEvaluate = { ...studyCriteria };

    if (bruteForce.bestResult) {
        criteriaToEvaluate.bruteForce = {
            id: 'bruteForce',
            name: 'Optimized T2 (Brute-Force)',
            type: 'brute-force',
            citation: 'current study',
            parameters: bruteForce.bestResult.parameters,
        };
    }
    
    for (const key in criteriaToEvaluate) {
        const criterion = criteriaToEvaluate[key];
        const evaluations = processedData.map(p => evaluatePatient(p, criterion));
        const predictions = evaluations.map(e => e.prediction);
        const scores = evaluations.map(e => e.score);

        const metrics = calculateDiagnosticMetrics(predictions, groundTruth);
        const roc = calculateRocCurve(scores, groundTruth);

        allStats[criterion.id] = {
            ...metrics,
            auc: roc.auc,
            predictions: predictions,
            scores: scores,
            name: criterion.name,
            id: criterion.id
        };
    }

    // Perform comparison tests
    const avocadoResults = allStats.LurzSchaefer;
    for (const key in allStats) {
        if (key !== 'LurzSchaefer') {
            const otherResults = allStats[key];
            allStats[key].comparison = {
                mcnemar: mcnemarTest(avocadoResults.predictions, otherResults.predictions, groundTruth),
                delong: delongTest(avocadoResults.scores, otherResults.scores, groundTruth)
            };
        }
    }

    return allStats;
}

function generatePublicationText(stats, patientData) {
    if (!stats || Object.keys(stats).length === 0) {
        return { materials: '', results: '' };
    }

    const formatPercent = (metric) => `${formatNumber(metric.value * 100, 1)}% (95% CI: ${formatNumber(metric.lower * 100, 1)}%–${formatNumber(metric.upper * 100, 1)}%)`;
    const formatPValue = (p) => p < 0.001 ? '< .001' : `= ${formatNumber(p, 3)}`;

    // Materials and Methods
    const materials = `
        <h3>Statistical Analysis</h3>
        <p class="publication-text">
            All statistical analyses were performed using custom software developed for this study (AvocadoSign App v2.6). 
            Diagnostic performance metrics, including sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and accuracy, were calculated for each criterion. 
            Exact 95% confidence intervals (CIs) for these binomial proportions were determined using the Clopper-Pearson method.
            Receiver operating characteristic (ROC) curves were generated by plotting sensitivity against 1-specificity across all possible thresholds. 
            The area under the curve (AUC) was calculated for each criterion. To compare the diagnostic performance between the Avocado Sign and the established T2-weighted imaging criteria, 
            the DeLong test was used for statistical comparison of AUCs. Additionally, the McNemar test was employed to compare the sensitivity and specificity of paired diagnostic tests. 
            A p-value of less than .05 was considered to indicate a statistically significant difference.
        </p>
    `;

    // Results
    const patientCount = patientData.length;
    const maleCount = patientData.filter(p => p.geschlecht === 'm').length;
    const femaleCount = patientCount - maleCount;
    const ageData = patientData.map(p => p.age).filter(age => age !== null);
    const meanAge = ageData.reduce((a, b) => a + b, 0) / ageData.length;
    const minAge = Math.min(...ageData);
    const maxAge = Math.max(...ageData);
    const nPositiveCount = patientData.filter(p => p.groundTruth === 1).length;

    let results = `
        <h3>Patient Cohort</h3>
        <p class="publication-text">
            A total of ${patientCount} patients were included in this study, consisting of ${maleCount} men and ${femaleCount} women. 
            The mean age of the cohort was ${formatNumber(meanAge, 1)} years (range, ${minAge}–${maxAge} years). 
            Histopathological analysis confirmed lymph node metastases (N+) in ${nPositiveCount} of ${patientCount} patients (${formatNumber((nPositiveCount/patientCount)*100, 1)}%).
        </p>
        <h3>Diagnostic Performance</h3>
    `;

    const renderResultText = (criterion) => {
        return `<p class="publication-text">
            The ${criterion.name} demonstrated a sensitivity of ${formatPercent(criterion.sensitivity)}, a specificity of ${formatPercent(criterion.specificity)}, 
            a PPV of ${formatPercent(criterion.ppv)}, an NPV of ${formatPercent(criterion.npv)}, and an accuracy of ${formatPercent(criterion.accuracy)}. 
            The AUC for this criterion was ${formatNumber(criterion.auc.value, 3)}.
        </p>`;
    };

    results += renderResultText(stats.LurzSchaefer);
    results += renderResultText(stats.Brown);
    results += renderResultText(stats.Koh);
    results += renderResultText(stats.Horvat);
    if(stats.bruteForce) {
        results += renderResultText(stats.bruteForce);
    }
    
    results += `<h3>Performance Comparison</h3>`;
    
    const renderComparisonText = (criterion) => {
        if (!criterion.comparison) return '';
        const delongP = formatPValue(criterion.comparison.delong.pValue);
        const sigDiffText = criterion.comparison.delong.pValue < 0.05 ? 'significantly higher' : 'not significantly different';

        return `<p class="publication-text">
            The AUC of the Avocado Sign (${formatNumber(stats.LurzSchaefer.auc.value, 3)}) was ${sigDiffText} than that of the ${criterion.name} (${formatNumber(criterion.auc.value, 3)}, p ${delongP}).
        </p>`;
    };
    
    results += renderComparisonText(stats.Brown);
    results += renderComparisonText(stats.Koh);
    results += renderComparisonText(stats.Horvat);
    if(stats.bruteForce) {
        results += renderComparisonText(stats.bruteForce);
    }

    return { materials, results };
}


export function renderPublicationTab(state) {
    const container = getElement('#publication-output');
    clearContainer(container);
    
    const fullStats = getFullStatistics(state);
    
    if (!fullStats) {
        container.textContent = 'Statistiken müssen zuerst berechnet werden.';
        return;
    }

    const { materials, results } = generatePublicationText(fullStats, state.processedData);

    const materialsSection = createElement('div', { classes: ['publication-section'] });
    materialsSection.innerHTML = `<h2>Material and Methods</h2>${materials}`;
    
    const resultsSection = createElement('div', { classes: ['publication-section'] });
    resultsSection.innerHTML = `<h2>Results</h2>${results}`;

    container.appendChild(materialsSection);
    container.appendChild(resultsSection);
}
